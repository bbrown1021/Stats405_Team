{"about": "music data", "codebook": {"id": "observation id particular to this WM project", "hit": "The target variable for the track. It can be either ‘0’ or ‘1’. ‘1’ implies that this song has\nfeatured in the weekly list (Issued by Billboards) of Hot-100 tracks in that decade at least\nonce and is therefore a ‘hit’. ‘0’ Implies that the track is a ‘flop’.", "key": "The estimated overall key of the track. Integers map to pitches using standard Pitch\nClass notation. E.g. 0 = C, 1 = C#/Db, 2 = D, and so on. If no key was detected, the value is -\n1.", "uri": "The resource identifier for the track.", "mode": "Mode indicates the modality (major or minor) of a track, the type of scale from which\nits melodic content is derived. Major is represented by 1 and minor is 0.", "tempo": "The overall estimated tempo of a track in beats per minute (BPM). In musical\nterminology, tempo is the speed or pace of a given piece and derives directly from the\naverage beat duration.", "track": "The Name of the track.", "artist": "The Name of the Artist", "decade": "added by us so we could send all the data in one file. Decade was not included as a\nvariable in the original data. It was added using the file name at time of file reading.", "energy": "Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of\nintensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example,\ndeath metal has high energy, while a Bach prelude scores low on the scale. Perceptual\nfeatures contributing to this attribute include dynamic range, perceived loudness, timbre,\nonset rate, and general entropy", "valence": "A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a\ntrack. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while\ntracks with low valence sound more negative (e.g. sad, depressed, angry).", "liveness": "Detects the presence of an audience in the recording. Higher liveness values\nrepresent an increased probability that the track was performed live. A value above 0.8\nprovides strong likelihood that the track is live.", "loudness": "The overall loudness of a track in decibels (dB). Loudness values are averaged\nacross the entire track and are useful for comparing relative loudness of tracks. Loudness is\nthe quality of a sound that is the primary psychological correlate of physical strength\n(amplitude). Values typical range between -60 and 0 db.", "sections": "The number of sections the particular track has. This feature was extracted from\nthe data recieved by the API call for Audio Analysis of that particular track.", "chorus_hit": "This the the author’s best estimate of when the chorus would start for the track.\nIts the timestamp of the start of the third section of the track (in milliseconds). This feature\nwas extracted from the data recieved by the API call for Audio Analysis of that particular\ntrack.", "duration_ms": "The duration of the track in milliseconds. (1 second = 1000 ms)", "speechiness": "Speechiness detects the presence of spoken words in a track. The more\nexclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0\nthe attribute value. Values above 0.66 describe tracks that are probably made entirely of\nspoken words. Values between 0.33 and 0.66 describe tracks that may contain both music\nand speech, either in sections or layered, including such cases as rap music. Values below\n0.33 most likely represent music and other non-speech-like tracks.", "acousticness": "A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0\nrepresents high confidence the track is acoustic.", "danceability": "Danceability describes how suitable a track is for dancing based on a\ncombination of musical elements including tempo, rhythm stability, beat strength, and overall\nregularity. A value of 0.0 is least danceable and 1.0 is most danceable.", "time_signature": ": An estimated overall time signature of a track. The time signature (meter) is\na notational convention to specify how many beats are in each bar (or measure)", "instrumentalness": "Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are\ntreated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The\ncloser the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal\ncontent. Values above 0.5 are intended to represent instrumental tracks, but confidence is\nhigher as the value approaches 1.0."}}
